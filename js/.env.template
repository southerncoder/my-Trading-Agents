# Trading Agents Environment Configuration
# Copy this file to .env and fill in your API keys

# ===== LLM Provider Configuration =====
# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google AI
GOOGLE_API_KEY=your_google_ai_api_key_here

# LM Studio (Local)
LM_STUDIO_BASE_URL=http://your-lm-studio-host:port/v1
# Optional admin endpoint for LM Studio to request model load/unload
LM_STUDIO_ADMIN_URL=http://your-lm-studio-host:port/admin
# TTL (ms) for caching model loaded state to avoid excessive polling
LM_STUDIO_MODEL_CACHE_TTL_MS=30000

# OpenRouter
OPENROUTER_API_KEY=your_openrouter_api_key_here

# ===== Data Provider Configuration =====
# Finnhub
FINNHUB_API_KEY=your_finnhub_api_key_here

# Alpha Vantage (backup financial data)
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here

# News API
NEWS_API_KEY=your_news_api_key_here

# Reddit API (for social sentiment)
REDDIT_CLIENT_ID=your_reddit_client_id_here
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here
REDDIT_USER_AGENT=TradingAgents/1.0

# ===== Application Configuration =====
NODE_ENV=production
LOG_LEVEL=info

# Directory Settings
TRADINGAGENTS_RESULTS_DIR=./results
TRADINGAGENTS_DATA_DIR=./data
TRADINGAGENTS_EXPORTS_DIR=./exports
TRADINGAGENTS_CACHE_DIR=./cache
TRADINGAGENTS_LOGS_DIR=./logs
TRADINGAGENTS_PROJECT_DIR=./project

# Rate limiting
API_RATE_LIMIT_REQUESTS=100
API_RATE_LIMIT_WINDOW_MS=60000

# Cache settings
CACHE_TTL_SECONDS=300
REDIS_URL=redis://your-redis-host:port

# ===== Security Settings =====
# JWT secret for authentication (if implementing web interface)
JWT_SECRET=your_jwt_secret_here

# Encryption key for sensitive data
ENCRYPTION_KEY=your_encryption_key_here

# ===== Monitoring & Logging =====
# Application insights / monitoring
APPINSIGHTS_INSTRUMENTATIONKEY=your_appinsights_key_here

# Log file path
LOG_FILE_PATH=/app/logs/trading-agents.log

# ===== Database (if implementing persistence) =====
DATABASE_URL=postgresql://username:password@host:port/database_name

# ===== Performance Settings =====
# Maximum concurrent LLM requests
MAX_CONCURRENT_LLM_REQUESTS=5

# Request timeout in milliseconds
REQUEST_TIMEOUT_MS=30000

# Memory limits
MAX_MEMORY_USAGE_MB=800