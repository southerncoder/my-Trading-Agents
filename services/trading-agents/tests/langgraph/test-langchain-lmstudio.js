/**
 * LangChain + LM Studio Integration Test  
 * Tests LangChain ChatOpenAI with LM Studio configuration
 */

async function testLangChainIntegration() {
  console.log('ğŸ”— Testing LangChain + LM Studio Integration');
  console.log('='.repeat(50));
  
  try {
    console.log('ğŸ“¦ Importing ChatOpenAI...');
    const { ChatOpenAI } = await import('@langchain/openai');
    
    console.log('ğŸ”§ Creating ChatOpenAI instance for LM Studio...');
    const model = new ChatOpenAI({
      modelName: 'microsoft/phi-4-mini-reasoning',
      openAIApiKey: 'not-needed-for-local',
      configuration: {
        baseURL: 'http://localhost:1234/v1'
      },
      temperature: 0.1,
      maxTokens: 100,
      timeout: 30000 // 30 second timeout
    });
    
    console.log('ğŸ’¬ Testing simple invoke...');
    const startTime = Date.now();
    
    const response = await model.invoke([
      { role: 'user', content: 'Say "LangChain + LM Studio working!" in exactly those words.' }
    ]);
    
    const duration = Date.now() - startTime;
    
    console.log('âœ… LangChain integration successful!');
    console.log(`â±ï¸  Response time: ${duration}ms`);
    console.log(`ğŸ“ Response: "${response.content}"`);
    
    return { success: true, model, duration };
  } catch (error) {
    console.log(`âŒ LangChain integration failed: ${error.message}`);
    console.log(`ğŸ“‹ Error type: ${error.constructor.name}`);
    
    if (error.message.includes('timeout')) {
      console.log('â° This appears to be a timeout issue');
      console.log('ğŸ’¡ The model might be slow or busy');
    }
    
    return { success: false, model: null, error };
  }
}

async function testModelProviderWrapper() {
  console.log('\nğŸ­ Testing ModelProvider Wrapper');
  console.log('='.repeat(50));
  
  try {
    console.log('ğŸ“¦ Importing ModelProvider...');
    const { ModelProvider } = await import('../../dist/models/provider.js');
    
    console.log('ğŸ”§ Creating model with extended timeout...');
    const config = {
      provider: 'remote_lmstudio',
      modelName: 'microsoft/phi-4-mini-reasoning',
      baseURL: 'http://localhost:1234/v1',
      temperature: 0.1,
      maxTokens: 100,
      timeout: 60000 // 60 second timeout
    };
    
    const model = ModelProvider.createModel(config);
    
    console.log('ğŸ’¬ Testing ModelProvider invoke...');
    const startTime = Date.now();
    
    const response = await model.invoke([
      { role: 'user', content: 'Respond with "ModelProvider test successful"' }
    ]);
    
    const duration = Date.now() - startTime;
    
    console.log('âœ… ModelProvider test successful!');
    console.log(`â±ï¸  Response time: ${duration}ms`);
    console.log(`ğŸ“ Response: "${response.content}"`);
    
    return { success: true, duration };
  } catch (error) {
    console.log(`âŒ ModelProvider test failed: ${error.message}`);
    console.log(`ğŸ“‹ Error details: ${error.stack}`);
    return { success: false, error };
  }
}

async function runLangChainTest() {
  console.log('ğŸš€ LANGCHAIN + LM STUDIO INTEGRATION TEST');
  console.log('Testing LangChain wrapper with microsoft/phi-4-mini-reasoning');
  console.log('='.repeat(60));
  
  // Test 1: Direct LangChain integration
  const langchainResult = await testLangChainIntegration();
  
  // Test 2: ModelProvider wrapper
  const providerResult = await testModelProviderWrapper();
  
  // Summary
  console.log('\nğŸ“Š INTEGRATION TEST RESULTS');
  console.log('='.repeat(50));
  console.log(`ğŸ”— LangChain Direct: ${langchainResult.success ? 'âœ… WORKING' : 'âŒ FAILED'}`);
  console.log(`ğŸ­ ModelProvider: ${providerResult.success ? 'âœ… WORKING' : 'âŒ FAILED'}`);
  
  if (langchainResult.success && providerResult.success) {
    console.log('\nğŸ‰ ALL TESTS PASSED!');
    console.log('âœ¨ LangChain + LM Studio integration is working correctly');
    console.log('âš¡ Ready to test agents with longer timeouts');
    
    const avgTime = ((langchainResult.duration + providerResult.duration) / 2);
    console.log(`ğŸ“Š Average response time: ${avgTime.toFixed(0)}ms`);
    
    if (avgTime > 10000) {
      console.log('âš ï¸  Response times are slow (>10s)');
      console.log('ğŸ’¡ Consider using a faster model or increasing timeouts');
    }
  } else {
    console.log('\nâŒ INTEGRATION ISSUES DETECTED');
    
    if (!langchainResult.success) {
      console.log('ğŸ”§ LangChain integration failed - check configuration');
    }
    
    if (!providerResult.success) {
      console.log('ğŸ”§ ModelProvider failed - check wrapper implementation');
    }
  }
  
  return langchainResult.success && providerResult.success;
}

// Run test
runLangChainTest()
  .then(success => {
    console.log(`\nğŸ Integration test ${success ? 'PASSED' : 'FAILED'}`);
    process.exit(success ? 0 : 1);
  })
  .catch(error => {
    console.error('ğŸ’¥ Test crashed:', error);
    process.exit(1);
  });