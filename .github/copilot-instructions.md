# Copilot Instructions for TradingAgents

## Critical Security Rule: Never Include Real Network Information

**MANDATORY**: Never include real IP addresses, usernames, passwords, client IDs, or other sensitive network information in source code, test files, documentation, or any repository files.

### Why This Matters

1. **Security Policy Violation**: Exposing internal network details creates security vulnerabilities
2. **Network Topology Exposure**: Real IPs reveal internal network structure
3. **Attack Surface**: Hardcoded credentials provide attack vectors for malicious actors
4. **Privacy Concerns**: Personal/internal information should never be public
5. **Professional Standards**: Public repositories must maintain security hygiene

### Correct Approach: Use Environment Variables and Generic Examples

```python
# ‚úÖ CORRECT - Use environment variables
REMOTE_LM_STUDIO_URL = os.getenv('REMOTE_LM_STUDIO_URL', 'http://localhost:1234')
NEO4J_URI = os.getenv('NEO4J_URI', 'bolt://localhost:7687')
REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID', 'your_client_id_here')

# ‚úÖ CORRECT - Use localhost in examples
base_url = 'http://localhost:1234/v1'
neo4j_uri = 'bolt://localhost:7687'

# ‚úÖ CORRECT - Use generic examples in documentation
# Example: Connect to your LM Studio server at http://your-server:1234
# Set REDDIT_CLIENT_ID=your_actual_client_id in .env.local
```

### INCORRECT Approach: Hardcoded Real Information

```python
# ‚ùå NEVER DO THIS - exposes real sensitive information
base_url = 'http://127.0.0.1:9876/v1'  # Real IP - SECURITY VIOLATION
reddit_client_id = 'abc123realid'      # Real client ID - SECURITY VIOLATION
username = 'real_username'              # Real username - SECURITY VIOLATION
```

### Security Best Practices

1. **Environment Variables**: Always use env vars for network endpoints and credentials
2. **Localhost Examples**: Use localhost or 127.0.0.1 in code examples
3. **Generic Documentation**: Use placeholders like "your-server", "your_client_id" in docs
4. **Configuration Files**: Keep real values in .env.local files (gitignored)
5. **Documentation Sanitization**: Replace real values with placeholders in all docs

**This rule applies to ALL files in the repository including source code, tests, documentation, and configuration examples.**

## File Organization Best Practices

**MANDATORY**: Follow established file organization patterns for maintainability and clarity.

### Component-Based Organization

When working with related functionality, organize files into component-specific folders:

```
docs/
‚îú‚îÄ‚îÄ reddit/           # Reddit integration documentation
‚îú‚îÄ‚îÄ zep-graphiti/     # Zep-Graphiti memory system docs
‚îî‚îÄ‚îÄ market-data/      # Market data provider documentation

js/src/providers/
‚îú‚îÄ‚îÄ reddit/           # Reddit-specific providers
‚îú‚îÄ‚îÄ zep-graphiti/     # Zep-Graphiti memory providers
‚îî‚îÄ‚îÄ market-data/      # Market data providers

js/tests/
‚îú‚îÄ‚îÄ reddit/           # Reddit integration tests
‚îú‚îÄ‚îÄ zep-graphiti/     # Zep-Graphiti tests
‚îî‚îÄ‚îÄ integration/      # Cross-component integration tests

js/examples/
‚îú‚îÄ‚îÄ reddit/           # Reddit usage examples
‚îú‚îÄ‚îÄ zep-graphiti/     # Memory system examples
‚îî‚îÄ‚îÄ market-data/      # Data provider examples
```

### File Organization Principles

1. **Component Isolation**: Group related files (providers, tests, docs, examples) by functional component
2. **Clear Naming**: Use descriptive folder names that match the component/feature
3. **Import Path Updates**: Always update import statements when moving files
4. **Documentation Co-location**: Keep component docs near component code
5. **Test Organization**: Mirror source structure in test directories

### When Moving Files

1. **Plan the Organization**: Identify all related files before moving
2. **Update Import Paths**: Fix all import statements to reflect new locations
3. **Verify Functionality**: Test that moved files still work correctly
4. **Update Documentation**: Ensure docs reflect new file locations
5. **Maintain Legacy Paths**: Consider creating legacy archives for major refactors

### Benefits of Good Organization

- **Improved Navigation**: Easier to find related files
- **Better Maintainability**: Clear separation of concerns
- **Enhanced Collaboration**: Team members can quickly locate relevant code
- **Reduced Coupling**: Component isolation reduces cross-dependencies
- **Simplified Testing**: Component-specific test organization

## Critical Rule: Always Use Graphiti Client

**MANDATORY**: When writing code that interacts with Zep-Graphiti, ALWAYS use the official Graphiti client library through the TypeScript client bridge instead of direct HTTP API calls.

### Why This Matters

1. **Proper Data Processing**: The Graphiti client handles internal data processing logic that direct HTTP calls bypass
2. **Search Indexing**: Client-side logic ensures data is properly indexed for search functionality
3. **Entity Extraction**: The client automatically extracts entities and relationships from episodes
4. **Embedding Generation**: Proper embedding generation and storage is handled by the client
5. **Graph Consistency**: The client maintains graph consistency and relationships

### Correct Approach: Use TypeScript Client Bridge

```typescript
// ‚úÖ CORRECT - Use the client-based memory provider
import { ZepGraphitiMemoryProvider, createZepGraphitiMemory } from '../providers/zep-graphiti-memory-provider-client';

// Create client-based memory provider
const memoryProvider = await createZepGraphitiMemory({
  sessionId: 'trading-session',
  userId: 'trading-agent'
}, {
  provider: 'openai',
  model: 'gpt-4o-mini',
  temperature: 0.3,
  maxTokens: 1000
});

// Add episodes using client bridge
await memoryProvider.addEpisode(
  'Trading Analysis', 
  'Market analysis content',
  EpisodeType.ANALYSIS,
  { recommendation: 'Buy signal detected' }
);

// Search using client bridge
const results = await memoryProvider.searchMemories(
  'What should I do about rising interest rates?',
  { maxResults: 10 }
);
```

### Python Client Bridge Integration

The TypeScript integration uses `graphiti_ts_bridge.py` to provide seamless access to the Python Graphiti client:

```python
# This is handled automatically by the TypeScript bridge
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.nodes import EpisodeType
from datetime import datetime, timezone

# Bridge automatically configures client with proper settings
graphiti = Graphiti(
    neo4j_uri,
    neo4j_user, 
    neo4j_password,
    llm_client=llm_client,
    embedder=embedder
)
```

### INCORRECT Approach: Direct HTTP Calls

```typescript
// ‚ùå NEVER DO THIS - bypasses client logic
const response = await fetch("http://localhost:8000/messages", {
  method: 'POST',
  body: JSON.stringify({...})
});
const searchResponse = await fetch("http://localhost:8000/search", {
  method: 'POST', 
  body: JSON.stringify({...})
});
```

### Key Client Bridge Methods to Use

1. **TypeScript Interface**:
   - `createZepGraphitiMemory()` - Factory for client-based provider
   - `memoryProvider.addEpisode()` - Add episodes through client bridge
   - `memoryProvider.searchMemories()` - Search through client bridge
   - `memoryProvider.testConnection()` - Health check through bridge

2. **Enhanced Financial Memory**:
   - `EnhancedFinancialMemory` - Wrapper for compatibility with existing interfaces
   - `addSituations()` - Compatible with FinancialSituationMemory interface
   - `getMemories()` - Compatible memory retrieval
   - `getProviderInfo()` - Provider information and metrics

3. **Client Bridge Features**:
   - Automatic Python client initialization
   - Cross-language type safety
   - Enterprise logging and error handling
   - Circuit breaker patterns for reliability
### Configuration Best Practices

1. **Use Client-Based Provider**: Always use `zep-graphiti-memory-provider-client.ts` 
2. **Environment Variables**: Configure through env vars for flexibility
3. **TypeScript Bridge**: Let bridge handle Python client configuration
4. **Error Handling**: Client bridge includes enterprise-grade error handling
5. **Logging**: Structured logging built into client bridge operations

### Integration Testing

When testing Zep-Graphiti integration:

1. **Use Client Bridge**: Always test through TypeScript client bridge
2. **Test Connection**: Use `memoryProvider.testConnection()` for health checks
3. **Episode Processing**: Allow time for client-side processing after adding episodes
4. **Search Validation**: Test search functionality through client bridge methods
5. **Integration Tests**: Use `tests/test-client-memory-integration.ts` as reference

### Architecture Overview

```
TypeScript Trading Agents
         ‚Üì
zep-graphiti-memory-provider-client.ts
         ‚Üì  
GraphitiClientBridge
         ‚Üì
graphiti_ts_bridge.py (Python bridge)
         ‚Üì
Official Graphiti Python Client
         ‚Üì
Neo4j Database
```

### Remember

- **Legacy Cleanup**: HTTP-based implementations are archived in `legacy/http-implementation/`
- **Client Processing**: All data processing happens in the Python client, not HTTP endpoints
- **Search Indexing**: Client-side search indexing ensures proper discoverability
- **Entity Extraction**: Automatic entity and relationship extraction through client
- **Enterprise Features**: Circuit breakers, retry logic, and structured logging included

**This rule applies to ALL new code that interacts with Zep-Graphiti services.**

## Command Line Requirements
Use cross-shell friendly commands so contributors on bash/zsh/cmd/PowerShell can run them unchanged. Vite-node drives TS/ESM execution.

### Standards
- **Shells**: bash/zsh/cmd/PowerShell all supported; prefer `npm run` for portability
- **Environment Variables**: Prefer `.env` files or `npm run` scripts; per-shell forms are acceptable when needed
- **Service Scripts**: PowerShell scripts provided for Windows; other shells may run equivalent `docker compose` commands directly
- **Node/TS Execution**: Use `npx vite-node` or npm scripts that call vite-node

### Cross-Shell Command Chaining Rules
- Prefer `npm run` scripts to avoid shell differences
- `&&` works in bash/cmd and PowerShell 7+; in older PowerShell, use `;` or separate lines
- Conditional chaining in PowerShell: `cmd1; if ($?) { cmd2 }`

Examples:
```
# Portable: via npm scripts (any shell)
npm run build
npm test

# Chain build then test (bash/cmd/PowerShell 7+)
npm run build && npm test

# PowerShell portable alternative
npm run build; if ($?) { npm test }
```

### Container-First Architecture
- **Docker Mandatory**: All services run in containers
- **Terminal Windows**: Services start in separate Windows Terminal windows
- **Orchestration**: Use `docker-compose` and PowerShell automation
- **Health Monitoring**: All containers include health checks

## Project Overview
- **TradingAgents**: TypeScript multi-agent LLM trading framework (In Active Development)
- **Status**: üöß Core Infrastructure Complete - Production Features in Development
- **Build System**: Modern Vite-based TypeScript with extensionless imports and ES modules
- **Core**: TypeScript in `js/` with LangGraph workflows and enhanced memory system
- **Memory**: Official Zep Graphiti (`zepai/graphiti:latest`) Docker integration with client-based architecture
- **CLI**: Interactive interface with modern dependency stack
- **Agents**: 12 specialized trading agents with structured logging
- **Quality**: Tests passing, zero vulnerabilities, comprehensive enhanced memory algorithms implemented

**Current Development Focus**: Several core components still contain placeholder implementations and require completion before production deployment.

## Architecture & Key Components

### Container Infrastructure
- **Official Zep Graphiti Service**: `zepai/graphiti:latest` with client-based TypeScript integration
- **Neo4j Database**: `neo4j:5.26.0` for knowledge graph storage
- **Docker Compose**: Multi-service orchestration with health checks
- **Service Scripts**: PowerShell automation for service management

### Core Orchestration
- **Enhanced Trading Graph**: `js/src/graph/enhanced-trading-graph.ts` - Main orchestrator with placeholder implementations in progress
- **Dual Execution Modes**: Traditional and LangGraph workflows

### Agent Implementation (12 Total)
- **Analysts (4)**: Market, Social, News, Fundamentals
- **Researchers (3)**: Bull, Bear researchers + Research Manager
- **Risk Management (4)**: Risky, Safe, Neutral analysts + Portfolio Manager
- **Trader (1)**: Trading strategy execution

### Interactive CLI System
- **Main Interface**: `js/src/cli/main.ts` - User experience orchestration with inquirer 12.x
- **Terminal UI**: Progress tracking and result formatting
- **Configuration**: Config management with save/load capabilities

### Modern Dependency Stack (August 2025)
- **Vite 5.x**: Modern build system with ES modules
- **ESLint 9.34.0**: Flat config with TypeScript integration
- **Chalk 5.6.0**: ESM imports for colorized output
- **Inquirer 12.9.4**: Modern prompt system
- **Winston 3.17.0**: Structured logging with trace correlation
- **Axios 1.11.0**: HTTP client with security enhancements
- **LangChain 0.3.x**: Updated with breaking changes resolved
- **TypeScript 5.x**: Extensionless imports compatible with modern bundlers

## Developer Workflows

### Development Setup
```powershell
# Start containerized memory services
Set-Location py_zep\
.\start-zep-services.ps1 -Build  # First time or after changes
.\start-zep-services.ps1         # Subsequent starts

# TypeScript development with Vite
Set-Location js\
npm install
npm run build                    # Vite build
npm run dev                      # Vite dev server (if needed)
npm run cli                      # Interactive CLI (uses vite-node)
```

### Running TS/ESM scripts with vite-node
```powershell
Set-Location js
npx vite-node tests/config/basic-config.test.ts

# Multiple commands: avoid &&
npm run build; if ($?) { npx vite-node tests/integration/agent-memory.test.ts }
```

### Testing & Validation
```powershell
# Start services first (required for memory tests)
Set-Location py_zep\
.\start-zep-services.ps1

# Run comprehensive test suite (100% pass rate)
Set-Location ..\js\
npm run test:all                 # Complete test suite
npm run test-enhanced            # Enhanced graph workflow tests
npm run test-components          # CLI component tests
npm run test-langgraph           # LangGraph integration tests
npm run test-modern-standards    # Modern standards compliance
npm run build                    # Verify TypeScript compilation
npm run lint                     # ESLint validation
```

### LLM Provider Configuration and Secrets Handling

- All secret values (model IDs, API keys, LM Studio URLs, and provider endpoints) MUST be kept out of tracked source, tests, and documentation.
- Use `py_zep/.env.local` (or project-level `.env.local`) to store all runtime secrets. Only commit `.env.local.example` with placeholder values.

Example (set these in `py_zep/.env.local`):
```powershell
# Example entries for py_zep/.env.local (DO NOT COMMIT)
OPENAI_API_KEY=<your_openai_or_lmstudio_api_key>
OPENAI_BASE_URL=<your_lm_studio_base_url>
EMBEDDING_MODEL=<your_embedding_model_id>
LM_STUDIO_URL=<your_lm_studio_base_url>
PRIMARY_LM_STUDIO_URL=<your_remote_lm_studio_admin_url>
```

The codebase and tests will read `.env.local` when present. Do not add concrete model names or URLs in code or docs.

## Current Status & Recent Achievements

### ‚úÖ August 30, 2025 - Vite Migration & Test Coverage Complete
- **Modern Build System**: Complete migration to Vite 5.x with ES module support
- **Test Suite**: 100% test pass rate (9/9 tests) with comprehensive coverage
- **Module Resolution**: Modern bundler-based approach with vite-node
- **Import Standardization**: All imports converted to src/ paths
- **Constructor Fixes**: Resolved EnhancedTradingAgentsGraph instantiation issues

### ‚úÖ August 28, 2025 - Infrastructure Complete
- **Official Docker Integration**: `zepai/graphiti:latest` with client-based architecture
- **Security Audit**: 0 vulnerabilities found, all secrets externalized
- **Memory Integration**: Episodes working through client bridge
- **Neo4j 5.26.0**: Upgraded per documentation requirements

### ‚úÖ August 2025 - Modernization Complete
- **LangChain 0.3 Migration**: All breaking changes resolved
- **Dependency Modernization**: ESLint 9.x, Chalk 5.x, Inquirer 12.x, Winston 3.17.x
- **Enterprise Logging**: Winston-based structured logging
- **CLI Modernization**: Inquirer 12.x migration with 35+ prompts converted

### Service Management Best Practices
- **Use dedicated terminal windows** for services
- **Windows**: Use PowerShell scripts; **Other shells**: use `docker compose`
- **Official Docker images only**: zepai/graphiti:latest and neo4j:5.26.0
- **Include health checks** in container configurations
- **Use client bridge for development** (not direct API calls)

## Technical Innovations & Lessons Learned

### Comprehensive Dependency Modernization Achievement (August 2025)
- **Challenge**: Complex breaking changes across multiple major dependencies
- **Solution**: Phased migration approach with comprehensive testing and validation
- **Achievement**: Successfully modernized 17 dependencies with zero breaking changes
- **Impact**: Current enterprise standards, enhanced security, improved developer experience

### Vite Build System & Modern Module Resolution (August 30, 2025)
- **Challenge**: Legacy ts-node/tsx execution causing import resolution and .js extension issues
- **Solution**: Complete migration to Vite 5.x with modern ES module and TypeScript support
- **Implementation**: `vite.config.ts` with TypeScript resolver, all scripts converted to vite-node
- **Achievement**: 100% test pass rate (9/9) with consistent build/test environment
- **Benefits**: 
  - Extensionless imports compatible with modern bundlers
  - Faster test execution via Vite's optimized bundling
  - Consistent module resolution across development and testing
  - Future-proof build system aligned with modern JavaScript ecosystem

### LangChain 0.3 Migration Breakthrough 
- **Challenge**: Breaking API changes across core LangChain ecosystem
- **Solution**: Dynamic import strategy with runtime compatibility layer
- **Impact**: Future-proof integration that adapts to library evolution

### ESLint 9.x Flat Config Migration
- **Challenge**: Complete rewrite of ESLint configuration format
- **Solution**: Migrated from legacy .eslintrc to modern flat config
- **Achievement**: Full TypeScript integration with modern linting rules

### Inquirer 12.x API Restructure
- **Challenge**: Complete API breaking change from object-based to function-based prompts
- **Solution**: Converted 35+ CLI prompts to new individual function format
- **Impact**: Modern, maintainable CLI interface with better TypeScript support

### Enterprise-Grade Structured Logging System
- **Challenge**: Console statements throughout codebase unsuitable for production
- **Solution**: Comprehensive Winston-based structured logging with trace correlation
- **Implementation**: `js/src/utils/enhanced-logger.ts` with context-aware child loggers
- **Achievement**: 43 console statements replaced across 9+ agent files with zero breaking changes
- **Production Benefits**: 
  - JSON structured output for enterprise monitoring
  - Trace ID correlation for request tracking across workflows
  - Rich metadata and performance timing for debugging
  - Development-friendly colorized console with production-ready structured logs
- **Solution**: Migrated from legacy .eslintrc to modern flat config
- **Achievement**: Full TypeScript integration with modern linting rules

### Inquirer 12.x API Restructure
- **Challenge**: Complete API breaking change from object-based to function-based prompts
- **Solution**: Converted 35+ CLI prompts to new individual function format
- **Impact**: Modern, maintainable CLI interface with better TypeScript support

### Enterprise-Grade Structured Logging System
- **Challenge**: Console statements throughout codebase unsuitable for production
- **Solution**: Comprehensive Winston-based structured logging with trace correlation
- **Implementation**: `js/src/utils/enhanced-logger.ts` with context-aware child loggers
- **Achievement**: 43 console statements replaced across 9+ agent files with zero breaking changes
- **Production Benefits**: 
  - JSON structured output for enterprise monitoring
  - Trace ID correlation for request tracking across workflows
  - Rich metadata and performance timing for debugging
  - Development-friendly colorized console with production-ready structured logs

### Enterprise Performance Optimization Suite
- **Challenge**: Multi-agent framework needed production-level performance
- **Solution**: 5 comprehensive optimizations delivering massive improvements
- **Achievements**:
  - Parallel Execution: 15,000x speedup (16ms vs 240s sequential)
  - Intelligent Caching: LRU with TTL, 14.3% hit rate, automatic cleanup
  - Lazy Loading: 77% memory reduction through on-demand instantiation
### Containerized Memory Architecture
- **Challenge**: Complex Zep Graphiti Python service integration with TypeScript agents
- **Solution**: Full containerization with Docker Compose, TypeScript client bridge for seamless integration
- **Achievement**: Production-ready containerized memory service with client-based architecture
- **Benefits**: Complete service isolation, automated terminal management, client-based data processing
## Integration & External Dependencies

### Core Technologies
- **TypeScript 5.x**: Type safety and modern JavaScript features
- **Node.js 18+**: Runtime environment
- **Docker & Docker Compose**: Container orchestration and service isolation
- **LangChain & LangGraph**: LLM orchestration with advanced workflows
- **Inquirer.js, Chalk, Ora**: Interactive CLI with colored output and progress tracking

### PowerShell Service Scripts (August 2025)
- **`py_zep/start-zep-services.ps1`**: Complete service orchestration script
  - Builds Docker containers when needed
  - Starts services in dedicated terminal windows
  - Provides health check validation
  - Includes proper error handling and status reporting
- **Script Parameters**:
  - `-Build`: Force rebuild of containers
  - `-Fresh`: Clean start with volume removal
- **Usage Examples**:
  ```powershell
  .\start-zep-services.ps1 -Build    # First time setup
  .\start-zep-services.ps1          # Regular startup
  .\start-zep-services.ps1 -Fresh   # Clean restart
  ```

### LLM Providers
- **Cloud**: OpenAI (GPT-4), Anthropic (Claude), Google (Gemini)
- **Local**: LM Studio (recommended), Ollama
- **Multi-Provider**: OpenRouter for unified access

### Data Sources
- **Market Data**: Yahoo Finance, FinnHub APIs
- **Social/News**: Reddit, Google News APIs
- **Technical**: Custom indicators and calculations

## Usage Examples

### Interactive CLI (Primary Interface)
```powershell
npm run cli
# Interactive prompts guide through:
# - Ticker selection (e.g., AAPL)
# - Analyst configuration
# - LLM provider selection
# - Real-time progress tracking
# - Formatted results display
```

### Programmatic Usage
```typescript
import { EnhancedTradingAgentsGraph } from './src/graph/enhanced-trading-graph';

const graph = new EnhancedTradingAgentsGraph({
  enableLangGraph: true,
  llmProvider: 'lm_studio',
  selectedAnalysts: ['market', 'news']
});

const result = await graph.analyzeAndDecide('AAPL', '2025-08-24');
```

## Development Best Practices

### Code Standards
- Follow established TypeScript patterns and conventions with Vite-compatible imports
- Maintain 100% type safety - no `any` types without justification
- Use extensionless imports for all TypeScript files (compatible with modern bundlers)
- Use consistent error handling patterns throughout
- Document complex logic with JSDoc comments
- Follow the existing modular architecture
- All test files must use vite-node compatible imports and src/ paths

### Logging Best Practices (Production-Ready)
- **NEVER use console statements** in production code (CLI interface excepted for user output)
- Use `createLogger(context, component)` for structured logging with rich metadata
- Include trace IDs for request correlation across complex workflows
- Add performance timing with `logger.startTimer()` for operation metrics
- Provide contextual metadata in all log entries for debugging and monitoring
- Use appropriate log levels: debug, info, warn, error, critical

### Testing Approach
- Integration tests for complete workflows using vite-node execution
- Component tests for individual modules with 100% pass rate target
- Mock data for offline development and consistent test environments
- Runtime validation for dynamic APIs and LangGraph integrations
- All test imports must use src/ paths, never dist/ paths
- Comprehensive test suite covering CLI, System Integration, LangGraph, Performance, and Modern Standards

---

**Project Status**: üöß Core Infrastructure Complete - Production Features in Development
**Last Updated**: August 30, 2025 
**Recent Achievements**: Vite migration complete, 100% test coverage (9/9 tests), extensionless imports, modern build system, constructor fixes, comprehensive test suite validation
**Next Steps**: Enhanced Memory & Learning System implementation or Production Infrastructure development from comprehensive roadmap
**Current Development Focus**: Several core components still contain placeholder implementations and require completion before production deployment.
- Add performance timing with `logger.startTimer()` for operation metrics
- Provide contextual metadata in all log entries for debugging and monitoring
- Use appropriate log levels: debug, info, warn, error, critical

## Comprehensive Development Roadmap

### üß† Enhanced Memory & Learning (Priority: High)
- Advanced temporal reasoning with Zep Graphiti temporal knowledge graphs
- Cross-session learning and market pattern recognition capabilities
- Agent performance analytics and memory-driven trading insights
- Implementation: `js/src/memory/`, `js/src/learning/`, `js/src/patterns/`

### üèóÔ∏è Production Infrastructure (Priority: Very High)
- Multi-environment Docker orchestration with Kubernetes support
- API Gateway with authentication, rate limiting, and external access
- Prometheus/Grafana monitoring and alerting systems
- Load balancing and horizontal scaling capabilities
- Implementation: `docker/production/`, `api/`, `monitoring/`

### üìà Advanced Trading Features (Priority: High)
- Portfolio optimization using Modern Portfolio Theory
- Comprehensive backtesting framework with walk-forward analysis
- Real-time market data integration with WebSocket feeds
- Trading signal generation with confidence scoring and risk assessment
- Multi-asset support (crypto, forex, commodities, bonds, options)
- Technical analysis integration (chart patterns, indicators, momentum)
- Implementation: `js/src/portfolio/`, `js/src/backtesting/`, `js/src/signals/`

### üé® Enhanced User Experience (Priority: Medium)
- Web dashboard with React/Vue.js and real-time updates
- Advanced visualization using Chart.js/D3.js for market analytics
- Automated report generation with PDF/HTML templates
- Mobile Progressive Web App with offline capabilities
- Implementation: `web/`, `js/src/visualization/`, `js/src/reports/`

### üîå Integration & API Expansion (Priority: Medium)
- Additional data sources (Bloomberg, Alpha Vantage, IEX Cloud)
- Social media sentiment analysis (Twitter, Reddit WSB)
- Enhanced news processing with real-time sentiment scoring
- Webhook support for external notifications and triggers
- Third-party analytics integration (TradingView, Yahoo Finance Pro)
- Economic calendar integration (earnings, Fed announcements)
- Alternative data sources (satellite data, ESG metrics)
- Implementation: `js/src/integrations/`, `js/src/sentiment/`, `js/src/webhooks/`

### üî¨ Research & Development (Priority: Future)
- LLM fine-tuning on financial data for domain-specific performance
- Multi-modal analysis (chart OCR, document processing)
- Advanced agent coordination with consensus mechanisms
- Reinforcement learning framework for adaptive strategies
- Causal AI for understanding market cause-and-effect relationships
- Synthetic data generation for scenario testing
- Quantum computing integration for portfolio optimization
- Implementation: `research/`, `js/src/experimental/`, `models/`

### üìä Development Phases
1. **Phase 1 (Weeks 1-4)**: Enhanced Intelligence - Memory, Learning, Portfolio Optimization
2. **Phase 2 (Weeks 4-8)**: Production Ready - Infrastructure, API Gateway, Real-time Data
3. **Phase 3 (Weeks 6-10)**: User Experience - Web Dashboard, Visualization, Social Sentiment
4. **Phase 4 (Weeks 8-12)**: Advanced Features - Multi-Asset, Technical Analysis, News Processing
5. **Phase 5 (Weeks 10-16)**: Research & Innovation - AI Coordination, Multi-Modal, RL Framework

### üéØ Success Metrics
- **Performance**: <50ms response times, >80% signal accuracy
- **Availability**: 99.9% uptime, <2GB RAM per agent
- **Coverage**: 5+ asset classes, 10+ external APIs
- **Innovation**: 2 experimental features/quarter, 20% quarterly optimization gains
